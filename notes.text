// use mapParition() rather than map():
val vertices = sc.textFile(vertexIdFiles).map { line =>
            val fields = line.split(" ")
            (fields(0).toLong, fields(1))
        }.distinct()
//check how many partitions
vertices.numPartitions
// repartion num = 4x cores
val vertices.repartition(80).mapPartitions(getSecondDegreeNeighbors)

// graph.edgeListFile returns Graph[Int, Int], but VertexIds get expanded to Long, so...
// 1) md5 hash URL to get Integer and save to edge list file
// 2) load and process graph using Long

// For Python Spark jobs, make sure Python dependencies are installed on every node!

val vertices_string = vertices.map{ line =>
     | (line._1.toLong, line._2)
     | }


val ranksByVertexId = vertices_string.join(ranks).map {
     | case (id, (vid, rank)) => (vid, rank)
     | }

// aggregate messages
def sendDstId(ec:EdgeContext[Int, Int, Array[Long]]):Unit = { ec.sendToDst(Array(ec.dstId)) }
val neighbors = graph.aggregateMessages[Array[Long]](sendDstId, _ ++ _)

// md5 hashing
import java.security.MessageDigest
import java.nio.ByteBuffer

def md5(s: String) = {
    MessageDigest.getInstance("MD5").digest(s.getBytes)
}

ByteBuffer.wrap(md5("Hello")).getLong
// res4: Long = -8423251567987060074

// Scala HBase API example
// http://wiki.apache.org/hadoop/Hbase/Scala
import org.apache.hadoop.hbase.HBaseConfiguration
import org.apache.hadoop.hbase.client.{HBaseAdmin,HTable,Put,Get}
import org.apache.hadoop.hbase.util.Bytes


val conf = new HBaseConfiguration()
val admin = new HBaseAdmin(conf)

// list the tables
val listtables=admin.listTables() 
listtables.foreach(println)

// let's insert some data in 'mytable' and get the row

val table = new HTable(conf, "mytable")

val theput= new Put(Bytes.toBytes("rowkey1"))

theput.add(Bytes.toBytes("ids"),Bytes.toBytes("id1"),Bytes.toBytes("one"))
table.put(theput)

val theget= new Get(Bytes.toBytes("rowkey1"))
val result=table.get(theget)
val value=result.value()
println(Bytes.toString(value))
println(Bytes.toString(Bytes.toBytes("ids"), Bytes.toBytes("URL")))
***********************************
//import org.apache.hadoop.hbase.client.HBaseAdmin
import org.apache.hadoop.hbase.client.Admin
import org.apache.hadoop.hbase.client.Table
import org.apache.hadoop.hbase.client.ConnectionFactory
import org.apache.hadoop.hbase.{HBaseConfiguration, HTableDescriptor, TableName}
import org.apache.hadoop.hbase.client.Put

val connection = ConnectionFactory.createConnection()
val admin = connection.getAdmin()
admin.tableExists(TableName.valueOf("websites"))
// res8: Boolean = true
val table = connection.getTable(TableName.valueOf("websites"))
// look up table.batch()
// https://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/Table.html

val getter = new Get("www.google.com".getBytes)

val writer = new Put(md5("www.google.com"))
// writer: org.apache.hadoop.hbase.client.Put = {"totalColumns":0,"families":{},"row":"\\x0A\\x13{7\\x5C\\xC3\\x88\\x1Ap\\xE1\\x86\\xCE!r\\xC8\\xD1"}

table.close()

// mesh.sbt
// warc-hadoop class
// https://github.com/ept/warc-hadoop
libraryDependencies += "com.martinkl.warc" % "warc-hadoop" % "0.1.0"

// JSON representation of desired HBase schema
{
    "google.com": // Row Key
    {
        "Data": // Column Family
        {
            "VertexId": // Column Qualifier
            {
                "Timestamp1" : "md5(google.com)" // Cell Value
            },
            "URL":
            {
                "Timestamp1" : "google.com"
            },
            "PageRank":
            {
                "Timestamp1" : "0.28"
            }
        },
        "Neighbors": // Column Family
        {
            "FirstDegree": // Column Qualifier
            {
                "Timestamp1": Array[String] // Cell Value
            },
            "SecondDegree":
            {
                "Timestamp1": Array[String]
            },
            "ThirdDegree":
            {
                "Timestamp1": Array[String]
            }
        }
    }
}

// create HBase Table
// create 'TableName', 'ColumnFamily1', 'ColumnFamily2', ...
hbase(main):001:0> create 'websites', 'Data', 'Neighbors'

// drop HBase TAble
hbase(main):002:0> disable 'websites'
hbase(main):003:0> drop 'websites'

// Handle Async calls in node
// http://stackoverflow.com/questions/10695629/node-js-express-next
function loadUser(req, res, next) {
  if (req.params.userId) {
    Users.findOne({ id: req.params.userId }, function(err, user) {
      if (err) {
        return next(new Error("Couldn't find user: " + err));
      }

      req.user = user;
      next();
    });
  } else {
    next();
  }
}

// ...

app.get('/user/:userId', loadUser, function(req, res) {
  // do something with req.user
});

app.get('/users/:userId?', loadUser, function(req, res) {
  // if req.user was set, it's because userId was specified (and we found the user).
});

// Pretend there's a "loadItem()" which operates similarly, but with itemId.
app.get('/item/:itemId/addTo/:userId', loadItem, loadUser, function(req, res) {
  req.user.items.append(req.item.name);
});
